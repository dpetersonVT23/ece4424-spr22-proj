{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUjxBED56Mmp"
   },
   "source": [
    "\n",
    "---\n",
    "# **License Plate Detection**\n",
    "##**David Peterson - ECE 4424 - Spring 2022 Project - AMLPR**\n",
    "---\n",
    "\n",
    "### **Data Loading and Pre-Processing**###\n",
    "1.   Mount Google Drive\n",
    "2.   Load original license plate image dataset - location labels\n",
    "3.   Modify original license plate image dataset structure for YOLOv3 integration\n",
    "\n",
    "**Dataset Modification Details:**  \n",
    "\n",
    "- Dataset Train-Test Split: 80% Train | 20% Train\n",
    "\n",
    "- File Structure in Detection Directory:\n",
    "> lp_loc_img_data (original)   \n",
    "> detection_data (modified)  \n",
    "> darknet   \n",
    "> classes.names  \n",
    "> darknet-yolov3-custom.cfg  \n",
    "> train.log  \n",
    "> yolov3.data  \n",
    "\n",
    "- Original format of dataset:  \n",
    "  - Separate train and test text files with image file paths and labels for each image\n",
    "> images/imageX.jpg  \n",
    "> imageX label   \n",
    "> ...\n",
    "\n",
    "- Modified format of dataset:   \n",
    "  - Separate train and test text files with only image file paths  \n",
    "  - Separate labels directory with text files for individual image labels\n",
    "\n",
    "  - Modify Label Format\n",
    "    - Current Label Format:  \n",
    "  > Top-Left X | Top-Left Y | Bottom-Right X | Bottom-Right Y \n",
    "\n",
    "    - Normalized Label Format:\n",
    "  > Class ID | Center-X | Center-Y | Width | Height\n",
    "\n",
    "  - File Structure in detection_data directory:\n",
    "> detection_train.txt  \n",
    "> detection_test.txt  \n",
    "> images  \n",
    "> weights  \n",
    "> labels  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1648749061998,
     "user": {
      "displayName": "David Peterson",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "Dw2HEe2YMtn2",
    "outputId": "e58dcf6f-0013-4795-b90f-e97c17d1a3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1648749068454,
     "user": {
      "displayName": "David Peterson",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "oRo2jOyU862d",
    "outputId": "94248596-f495-4928-e36e-cc78cfbaea58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to detection directory: /content/drive/MyDrive/ECE4424/Project/detection\n"
     ]
    }
   ],
   "source": [
    "# append the directory to your python path using sys\n",
    "import sys\n",
    "import os\n",
    "prefix = '/content/drive/MyDrive/'\n",
    "\n",
    "# customized path to detection directory\n",
    "cust_path_detection = 'ECE4424/Project/detection'\n",
    "sys_path = prefix + cust_path_detection\n",
    "sys.path.append(sys_path)\n",
    "\n",
    "print(\"Path to detection directory: {}\".format(sys_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1648749070095,
     "user": {
      "displayName": "David Peterson",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "NkUjquCN91qb",
    "outputId": "f2e6fc67-4a4f-4b3d-e546-65cffc7f257c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: {'/images/cars4_052.jpg': (202, 247, 270, 270), '/images/cars2_021.jpg': (292, 249, 375, 276), '/images/cars4_074.jpg': (156, 253, 224, 281), '/images/cars4_010.jpg': (280, 269, 348, 295), '/images/cars3_026.jpg': (297, 217, 358, 242), '/images/cars4_085.jpg': (273, 231, 343, 258), '/images/cars063.jpg': (323, 240, 400, 263), '/images/cars4_061.jpg': (238, 218, 324, 246), '/images/cars4_080.jpg': (400, 248, 475, 275), '/images/cars4_128.jpg': (257, 242, 329, 266), '/images/cars4_127.jpg': (260, 219, 334, 247), '/images/cars4_065.jpg': (296, 247, 383, 281), '/images/cars4_037.jpg': (431, 355, 504, 382), '/images/cars060.jpg': (326, 292, 395, 315), '/images/cars4_105.jpg': (409, 96, 497, 129), '/images/cars4_116.jpg': (253, 270, 308, 286), '/images/cars4_124.jpg': (289, 258, 368, 289), '/images/cars2_052.jpg': (379, 207, 459, 232), '/images/cars4_060.jpg': (250, 229, 334, 257), '/images/cars4_005.jpg': (270, 233, 361, 260), '/images/cars056.jpg': (214, 207, 290, 228), '/images/cars4_020.jpg': (184, 217, 254, 244), '/images/cars2_035.jpg': (340, 262, 434, 294), '/images/cars2_032.jpg': (311, 194, 395, 226), '/images/cars4_055.jpg': (214, 301, 285, 324), '/images/cars2_068.jpg': (367, 281, 447, 309), '/images/cars2_042.jpg': (347, 220, 425, 250), '/images/cars4_026.jpg': (207, 245, 267, 270), '/images/cars2_043.jpg': (371, 210, 459, 238), '/images/cars2_073.jpg': (285, 275, 357, 299), '/images/cars4_091.jpg': (274, 214, 350, 238), '/images/cars4_096.jpg': (249, 241, 314, 263), '/images/cars3_017.jpg': (240, 297, 311, 322), '/images/cars2_066.jpg': (341, 270, 418, 295), '/images/cars2_049.jpg': (393, 202, 477, 233), '/images/cars4_108.jpg': (252, 214, 325, 238), '/images/cars4_099.jpg': (267, 329, 339, 356), '/images/cars3_024.jpg': (359, 338, 435, 362), '/images/cars4_081.jpg': (259, 231, 338, 259), '/images/cars2_017.jpg': (354, 328, 441, 352), '/images/cars027.jpg': (214, 294, 290, 321), '/images/cars2_014.jpg': (388, 355, 489, 390), '/images/cars4_114.jpg': (220, 290, 290, 313), '/images/cars4_014.jpg': (301, 225, 378, 250), '/images/cars2_007.jpg': (220, 250, 306, 278), '/images/cars026.jpg': (264, 219, 340, 244), '/images/cars4_117.jpg': (236, 218, 320, 251), '/images/cars3_020.jpg': (341, 335, 409, 355), '/images/cars4_107.jpg': (249, 214, 328, 243), '/images/cars3_019.jpg': (337, 349, 413, 371), '/images/cars061.jpg': (305, 288, 376, 312), '/images/cars4_092.jpg': (134, 359, 216, 387), '/images/cars066.jpg': (336, 249, 405, 271), '/images/cars2_061.jpg': (362, 204, 455, 230), '/images/cars4_054.jpg': (314, 337, 389, 366), '/images/cars2_005.jpg': (391, 329, 480, 356), '/images/cars4_033.jpg': (243, 226, 327, 253), '/images/cars3_011.jpg': (280, 242, 365, 270), '/images/cars036.jpg': (181, 282, 271, 314), '/images/cars4_073.jpg': (310, 308, 396, 337), '/images/cars070.jpg': (297, 210, 359, 234), '/images/cars2_045.jpg': (353, 210, 455, 244), '/images/cars4_015.jpg': (361, 238, 433, 267), '/images/cars4_008.jpg': (320, 292, 394, 318), '/images/cars2_044.jpg': (450, 286, 540, 318), '/images/cars4_083.jpg': (257, 231, 336, 254), '/images/cars032.jpg': (223, 214, 307, 241), '/images/cars065.jpg': (310, 211, 380, 234), '/images/cars040.jpg': (224, 307, 303, 335), '/images/cars4_069.jpg': (164, 208, 224, 229), '/images/cars3_013.jpg': (331, 352, 428, 381), '/images/cars4_109.jpg': (241, 198, 307, 223), '/images/cars2_025.jpg': (359, 246, 438, 273), '/images/cars4_007.jpg': (254, 304, 314, 323), '/images/cars4_129.jpg': (271, 206, 342, 231), '/images/cars2_010.jpg': (265, 215, 353, 243), '/images/cars4_030.jpg': (170, 364, 239, 385), '/images/cars4_097.jpg': (321, 309, 399, 337), '/images/cars3_007.jpg': (305, 269, 389, 294), '/images/cars4_019.jpg': (286, 218, 364, 250), '/images/cars4_048.jpg': (220, 205, 313, 237), '/images/cars4_113.jpg': (273, 184, 363, 212), '/images/cars2_034.jpg': (393, 296, 488, 321), '/images/cars4_039.jpg': (268, 255, 358, 289), '/images/cars3_031.jpg': (335, 237, 407, 262), '/images/cars4_126.jpg': (307, 239, 373, 261), '/images/cars4_131.jpg': (253, 220, 313, 242), '/images/cars4_110.jpg': (293, 246, 388, 278), '/images/cars3_027.jpg': (335, 234, 393, 255), '/images/cars3_021.jpg': (327, 333, 403, 357), '/images/cars4_056.jpg': (213, 229, 289, 256), '/images/cars3_010.jpg': (311, 311, 388, 339), '/images/cars3_009.jpg': (358, 221, 432, 246), '/images/cars4_125.jpg': (202, 261, 294, 293), '/images/cars4_040.jpg': (252, 235, 346, 267), '/images/cars052.jpg': (190, 222, 264, 250), '/images/cars2_012.jpg': (358, 227, 445, 256), '/images/cars4_122.jpg': (302, 237, 378, 262), '/images/cars2_056.jpg': (403, 196, 489, 223), '/images/cars045.jpg': (280, 267, 352, 296), '/images/cars3_008.jpg': (382, 334, 465, 363), '/images/cars4_123.jpg': (244, 209, 325, 239), '/images/cars2_051.jpg': (315, 202, 395, 229), '/images/cars4_088.jpg': (276, 236, 359, 266), '/images/cars058.jpg': (301, 285, 373, 307), '/images/cars2_008.jpg': (380, 359, 470, 384), '/images/cars2_002.jpg': (305, 212, 388, 237), '/images/cars2_016.jpg': (381, 356, 464, 378), '/images/cars4_031.jpg': (312, 335, 388, 360), '/images/cars057.jpg': (240, 198, 310, 220), '/images/cars4_034.jpg': (236, 228, 320, 256), '/images/cars051.jpg': (211, 214, 286, 244), '/images/cars2_046.jpg': (405, 206, 474, 229), '/images/cars4_120.jpg': (246, 264, 302, 289), '/images/cars2_064.jpg': (332, 215, 401, 238), '/images/cars3_001.jpg': (373, 279, 440, 301), '/images/cars4_042.jpg': (338, 231, 411, 258), '/images/cars2_029.jpg': (338, 219, 398, 236), '/images/cars4_072.jpg': (202, 237, 279, 266), '/images/cars4_041.jpg': (201, 178, 296, 211), '/images/cars4_011.jpg': (336, 217, 397, 241), '/images/cars4_036.jpg': (290, 282, 365, 312), '/images/cars2_013.jpg': (255, 198, 350, 226), '/images/cars3_015.jpg': (359, 237, 446, 268), '/images/cars4_104.jpg': (224, 194, 316, 226), '/images/cars069.jpg': (323, 234, 387, 256), '/images/cars2_015.jpg': (401, 223, 486, 251), '/images/cars4_017.jpg': (180, 316, 256, 347), '/images/cars4_103.jpg': (82, 263, 171, 290), '/images/cars2_004.jpg': (338, 204, 424, 231), '/images/cars2_003.jpg': (289, 230, 372, 254), '/images/cars2_027.jpg': (274, 284, 348, 311), '/images/cars4_089.jpg': (356, 228, 435, 254), '/images/cars4_077.jpg': (230, 246, 314, 273), '/images/cars4_112.jpg': (241, 221, 320, 249), '/images/cars4_119.jpg': (262, 216, 349, 244), '/images/cars4_063.jpg': (226, 235, 309, 261), '/images/cars2_069.jpg': (371, 193, 451, 224), '/images/cars2_033.jpg': (369, 233, 459, 265), '/images/cars4_035.jpg': (221, 188, 291, 212), '/images/cars2_026.jpg': (212, 252, 289, 278), '/images/cars2_074.jpg': (348, 365, 430, 393), '/images/cars4_045.jpg': (247, 258, 317, 281), '/images/cars2_006.jpg': (435, 350, 518, 376), '/images/cars2_019.jpg': (461, 408, 568, 439), '/images/cars2_038.jpg': (371, 220, 439, 250), '/images/cars2_072.jpg': (340, 220, 411, 241), '/images/cars2_011.jpg': (316, 294, 408, 328), '/images/cars3_003.jpg': (235, 284, 302, 310), '/images/cars3_014.jpg': (379, 355, 484, 383), '/images/cars4_130.jpg': (324, 237, 370, 255), '/images/cars2_028.jpg': (342, 245, 416, 271), '/images/cars4_057.jpg': (179, 228, 259, 260), '/images/cars031.jpg': (202, 222, 287, 252), '/images/cars4_064.jpg': (248, 361, 348, 391), '/images/cars2_067.jpg': (374, 274, 460, 300), '/images/cars2_037.jpg': (369, 183, 440, 209), '/images/cars3_023.jpg': (274, 347, 360, 379), '/images/cars2_009.jpg': (330, 226, 404, 252), '/images/cars2_024.jpg': (409, 249, 494, 280), '/images/cars4_003.jpg': (302, 267, 368, 288), '/images/cars4_009.jpg': (239, 223, 306, 249), '/images/cars2_036.jpg': (224, 285, 319, 313), '/images/cars055.jpg': (199, 285, 280, 309), '/images/cars2_059.jpg': (376, 318, 465, 346), '/images/cars2_055.jpg': (448, 332, 531, 363), '/images/cars4_111.jpg': (277, 272, 360, 304), '/images/cars067.jpg': (298, 220, 367, 243), '/images/cars2_039.jpg': (364, 286, 434, 308), '/images/cars4_094.jpg': (212, 283, 283, 310), '/images/cars3_022.jpg': (303, 348, 393, 379), '/images/cars2_053.jpg': (371, 210, 451, 234), '/images/cars2_062.jpg': (324, 230, 415, 257), '/images/cars4_024.jpg': (218, 292, 285, 320), '/images/cars4_082.jpg': (221, 325, 309, 350), '/images/cars3_005.jpg': (358, 206, 426, 232), '/images/cars2_054.jpg': (283, 227, 372, 252), '/images/cars2_063.jpg': (414, 299, 476, 318), '/images/cars2_057.jpg': (396, 230, 491, 263), '/images/cars2_065.jpg': (298, 255, 379, 279), '/images/cars4_100.jpg': (196, 230, 269, 253), '/images/cars039.jpg': (268, 249, 355, 277), '/images/cars4_093.jpg': (235, 301, 319, 332), '/images/cars3_030.jpg': (361, 306, 426, 327), '/images/cars3_029.jpg': (335, 251, 423, 278), '/images/cars028.jpg': (206, 246, 283, 274), '/images/cars2_023.jpg': (391, 238, 477, 268), '/images/cars4_029.jpg': (251, 243, 331, 270), '/images/cars053.jpg': (239, 203, 315, 229), '/images/cars4_098.jpg': (198, 233, 269, 256), '/images/cars2_060.jpg': (409, 304, 498, 330), '/images/cars2_050.jpg': (334, 214, 418, 241), '/images/cars4_059.jpg': (223, 235, 300, 269), '/images/cars2_022.jpg': (327, 355, 415, 382), '/images/cars2_058.jpg': (379, 254, 465, 289), '/images/cars4_032.jpg': (252, 268, 321, 291)}\n",
      "Amount of Train Data: 196\n",
      "Test Data: {'/images/cars4_046.jpg': (241, 288, 315, 318), '/images/cars4_086.jpg': (348, 201, 433, 227), '/images/cars3_006.jpg': (294, 231, 369, 258), '/images/cars4_087.jpg': (284, 242, 386, 272), '/images/cars4_006.jpg': (297, 408, 409, 444), '/images/cars2_070.jpg': (316, 204, 388, 223), '/images/cars068.jpg': (305, 308, 377, 332), '/images/cars3_025.jpg': (98, 424, 191, 451), '/images/cars4_101.jpg': (170, 246, 250, 273), '/images/cars029.jpg': (117, 267, 196, 296), '/images/cars2_040.jpg': (339, 207, 419, 229), '/images/cars4_013.jpg': (276, 195, 340, 218), '/images/cars4_022.jpg': (98, 332, 170, 358), '/images/cars4_012.jpg': (264, 229, 341, 256), '/images/cars033.jpg': (229, 226, 315, 255), '/images/cars4_067.jpg': (240, 200, 317, 225), '/images/cars4_025.jpg': (249, 324, 318, 350), '/images/cars3_016.jpg': (322, 301, 399, 324), '/images/cars2_048.jpg': (366, 196, 438, 220), '/images/cars042.jpg': (257, 191, 334, 218), '/images/cars4_018.jpg': (254, 256, 325, 283), '/images/cars2_001.jpg': (404, 295, 478, 318), '/images/cars4_075.jpg': (290, 243, 370, 273), '/images/cars3_012.jpg': (308, 230, 379, 258), '/images/cars2_047.jpg': (408, 208, 482, 234), '/images/cars4_106.jpg': (198, 230, 292, 259), '/images/cars064.jpg': (332, 237, 397, 259), '/images/cars062.jpg': (195, 133, 264, 154), '/images/cars4_047.jpg': (296, 292, 367, 316), '/images/cars4_071.jpg': (390, 242, 486, 269), '/images/cars2_018.jpg': (363, 237, 451, 266), '/images/cars4_102.jpg': (252, 199, 331, 227), '/images/cars4_084.jpg': (159, 212, 237, 237), '/images/cars3_028.jpg': (369, 220, 459, 252), '/images/cars2_020.jpg': (347, 397, 455, 430), '/images/cars2_071.jpg': (217, 192, 291, 219), '/images/cars3_002.jpg': (338, 356, 408, 379), '/images/cars4_078.jpg': (239, 246, 317, 270), '/images/cars3_018.jpg': (369, 277, 445, 303), '/images/cars4_118.jpg': (263, 244, 314, 260), '/images/cars4_016.jpg': (321, 221, 401, 256), '/images/cars2_031.jpg': (331, 315, 406, 343), '/images/cars4_058.jpg': (193, 232, 267, 258), '/images/cars030.jpg': (166, 301, 253, 334), '/images/cars4_079.jpg': (311, 304, 381, 327), '/images/cars3_004.jpg': (290, 233, 357, 257), '/images/cars4_066.jpg': (281, 212, 355, 238), '/images/cars2_041.jpg': (439, 192, 521, 222), '/images/cars4_004.jpg': (298, 241, 377, 266), '/images/cars4_023.jpg': (273, 265, 356, 296)}\n",
      "Amount of Test Data: 50\n",
      "[STATUS] Original data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# initialize path constants\n",
    "LP_LOC_IMG_DATA_DIR_PATH = sys_path + \"/lp_loc_img_data\"              # path to original dataset directory\n",
    "TRAIN_DATA_FILE_PATH = LP_LOC_IMG_DATA_DIR_PATH + \"/train_data.txt\"   # path to train data file\n",
    "TEST_DATA_FILE_PATH = LP_LOC_IMG_DATA_DIR_PATH + \"/test_data.txt\"     # path to test data file\n",
    "\n",
    "# load train and test datasets\n",
    "train_data_file = open(TRAIN_DATA_FILE_PATH, \"r\")  # open train data file\n",
    "test_data_file = open(TEST_DATA_FILE_PATH, \"r\")    # open test data file\n",
    "\n",
    "# separate train data into file names and labels lists\n",
    "train_data_fps = []                                                         # initialize list for train data image file paths\n",
    "train_data_lbls = []                                                        # initialize list for train data labels\n",
    "for idx, line in enumerate(train_data_file):                                # for each line in the train data file\n",
    "    if not idx % 2:                                                             # if line index is even\n",
    "        train_data_fps.append(line.strip()[1:])                                     # append image file name to train data image file names list\n",
    "    else:                                                                       # else\n",
    "        train_data_lbls.append(tuple(map(int, line.strip().split(\",\"))))            # append label to train data label list as a tuple of integers\n",
    "\n",
    "# organize train data into file names:labels dictionary\n",
    "train_data = {}                                                             # initialize dictionary to store names:labels key:value pairs\n",
    "for idx in range(len(train_data_fps)):                                      # for each train image\n",
    "    train_data[train_data_fps[idx]] = train_data_lbls[idx]                      # insert file name-labels key-value pair\n",
    "\n",
    "# separate test data into file names and labels lists\n",
    "test_data_fps = []                                                          # initialize list for test data image file paths\n",
    "test_data_lbls = []                                                         # initialize list for test data labels\n",
    "for idx, line in enumerate(test_data_file):                                 # for each line in the test data file\n",
    "    if not idx % 2:                                                             # if line index is even\n",
    "        test_data_fps.append(line.strip()[1:])                                      # append image file name to test data image file names list\n",
    "    else:                                                                       # else\n",
    "        test_data_lbls.append(tuple(map(int, line.strip().split(\",\"))))             # append label to test data label list as a tuple of integers\n",
    "\n",
    "# organize test data into file names:labels dictionary\n",
    "test_data = {}                                                              # initialize dictionary to store names:labels key:value pairs\n",
    "for idx in range(len(test_data_fps)):                                       # for each test image\n",
    "    test_data[test_data_fps[idx]] = test_data_lbls[idx]                         # insert file name-labels key-value pair\n",
    "\n",
    "print(\"Train Data: {}\".format(train_data))\n",
    "print(\"Amount of Train Data: {}\".format(len(train_data)))\n",
    "print(\"Test Data: {}\".format(test_data))\n",
    "print(\"Amount of Test Data: {}\".format(len(test_data)))\n",
    "print(\"[STATUS] Original data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1648749074198,
     "user": {
      "displayName": "David Peterson",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "Rkcz8-ahGmKQ",
    "outputId": "cf00cff9-0add-414f-a806-c9aea94323cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] detection_train.txt created successfully.\n",
      "[STATUS] detection_test.txt created successfully.\n"
     ]
    }
   ],
   "source": [
    "# initialize path constants\n",
    "DETECTION_DATA_DIR_PATH = sys_path + \"/detection_data\"  # path to modified dataset directory\n",
    "\n",
    "# create detection_train.txt - contains paths for images in train data\n",
    "detection_train_file = open(DETECTION_DATA_DIR_PATH + \"/detection_train.txt\", \"w+\")  # open detection_train.txt in write mode - create if does not exist\n",
    "for fp in train_data.keys():                                                         # for each file path in train data\n",
    "    detection_train_file.write(DETECTION_DATA_DIR_PATH + fp + \"\\n\")                     # write the file path to detection_train.txt on a new line\n",
    "detection_train_file.close()                                                         # close detection_train.txt\n",
    "\n",
    "print(\"[STATUS] detection_train.txt created successfully.\")\n",
    "\n",
    "# create detection_test.txt - contains paths for images in test data\n",
    "detection_test_file = open(DETECTION_DATA_DIR_PATH + \"/detection_test.txt\", \"w+\")  # open detection_test.txt in write mode - create if does not exist\n",
    "for fp in test_data.keys():                                                        # for each file path in test data\n",
    "    detection_test_file.write(DETECTION_DATA_DIR_PATH + fp + \"\\n\")                    # write the file path to detection_test.txt on a new line\n",
    "detection_test_file.close()                                                        # close detection_test.txt\n",
    "\n",
    "print(\"[STATUS] detection_test.txt created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4116,
     "status": "ok",
     "timestamp": 1647477618797,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "7JyD-PILpaF6",
    "outputId": "c74dd2ed-c590-4a19-8547-3811f8b5cbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "# install python imaging library - Pillow\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647477620269,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "NS4uuxN0mYzn",
    "outputId": "d8b6deaa-c0da-4e57-b253-adea753e1846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize function compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# import Pillow - access image size\n",
    "from PIL import Image\n",
    "\n",
    "# function to normalize center coordinates (x, y), width, and height of the \n",
    "# ground-truth bounding box (gtbb) using the width and height of the given image\n",
    "# param img - path to image\n",
    "# param tlx - gtbb top-left x-coordinate\n",
    "# param tly - gtbb top-left y-coordinate\n",
    "# param brx - gtbb bottom-right x-coordinate\n",
    "# param bry - gtbb bottom-right y-coordinate\n",
    "def normalize(img, tlx, tly, brx, bry):\n",
    "    curr_img = Image.open(DETECTION_DATA_DIR_PATH + img)   # open current image using Pillow library\n",
    "    curr_img_w, curr_img_h = curr_img.size                 # access current image size\n",
    "\n",
    "    gtbb_cx = (tlx + brx) / 2                              # gtbb center-x\n",
    "    gtbb_cy = (tly + bry) / 2                              # gtbb center-y\n",
    "    gtbb_w = brx - tlx                                     # gtbb width\n",
    "    gtbb_h = bry - tly                                     # gtbb height\n",
    "\n",
    "    ncx = float(gtbb_cx / curr_img_w)                      # normalize gtbb center x-coordinate\n",
    "    ncy = float(gtbb_cy / curr_img_h)                      # normalize gtbb center y-coordinate \n",
    "    nw = float(gtbb_w / curr_img_w)                        # normalize gtbb width\n",
    "    nh = float(gtbb_h / curr_img_h)                        # normalize gtbb height\n",
    "    return ncx, ncy, nw, nh                                # return normalized center coordinates, width, and height\n",
    "\n",
    "print(\"[STATUS] Normalize function compiled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2301,
     "status": "ok",
     "timestamp": 1647482540307,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "dWhWQ2x-pJrJ",
    "outputId": "105c6aae-826a-4c09-b79f-57ddaac49fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label files for all data created successfully.\n"
     ]
    }
   ],
   "source": [
    "# import re (built-in) - multiple delimiters\n",
    "import re\n",
    "\n",
    "# initialize path constants\n",
    "DETECTION_LABELS_DIR_PATH = DETECTION_DATA_DIR_PATH + \"/labels\"   # path to labels directory\n",
    "\n",
    "# combine original train and test data image labels and file paths\n",
    "all_data = {}\n",
    "all_data.update(train_data)\n",
    "all_data.update(test_data)\n",
    "\n",
    "# create modified train and test data labels\n",
    "for fp, label in all_data.items():                                               # for each image\n",
    "    class_id = 0                                                                     # only 1 class => all labels have Class ID 0\n",
    "    ncx, ncy, nw, nh = normalize(fp, label[0], label[1], label[2], label[3])         # normalize ground truth bounding box center-coordinates, width, and height labels\n",
    "    fn = re.split(\"/|\\.\", fp)[2]                                                     # split image file path by '/' and '.' delimiters to obtain file name\n",
    "    label_file = open(DETECTION_LABELS_DIR_PATH + \"/\" + fn + \".txt\", \"w+\")           # open image label text file in write mode - create if does not exist\n",
    "    label_vals = (class_id, ncx, ncy, nw, nh)                                        # create list of final label values\n",
    "    for val in label_vals:                                                           # for each value in the final label\n",
    "        label_file.write(str(val) + \" \")                                                # write the final label values to the image label text file\n",
    "    label_file.close()                                                               # close image label text file\n",
    "\n",
    "print(\"[STATUS] Label files for all data created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpW8H8DpSqpg"
   },
   "source": [
    "### **Darknet Loading and Building**###\n",
    "\n",
    "1.   Clone Darknet (https://github.com/pjreddie/darknet)\n",
    "2.   Build Darknet\n",
    "3.   Modify Darknet files for custom fine-tuning and build again\n",
    "4.   Convert files to Unix format\n",
    "\n",
    "**Darknet File Modification Details:**  \n",
    "- Change rate of model file saving to be more often\n",
    "  - After first 1000 iterations (saving model every 100 iterations), modify to save model every 1000 iterations (changed from 10000)\n",
    "\n",
    "- Import starting weights from a pre-trained model (https://pjreddie.com/media/files/darknet53.conv.74)\n",
    "  - Fine tune model from pre-trained weights (opposed to random weights) to decrease learning time\n",
    "\n",
    "- Set paths to relevant files for training (yolov3.data)\n",
    "  - detection_train.txt\n",
    "  - detection_test.txt\n",
    "  - classes.names\n",
    "  - weights\n",
    "\n",
    "- Update YOLOv3 Configuration parameters\n",
    "  - Batch size, learning rate annealing, steps, number of convolutional filters, etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3314,
     "status": "ok",
     "timestamp": 1647472098012,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "huw6O1n3TJaw",
    "outputId": "fcd9b49a-a488-4a59-a140-ee80838e9acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/ECE4424/Project/detection/darknet\n",
      "make: Nothing to be done for 'all'.\n"
     ]
    }
   ],
   "source": [
    "# ensure working directory is detection directory\n",
    "# %cd /content/drive/MyDrive/ECE4424/Project/detection/\n",
    "\n",
    "# # clone Darknet \n",
    "# !git clone https://github.com/pjreddie/darknet\n",
    "\n",
    "# # change working directory to cloned Darknet directory in detection directory\n",
    "# %cd /content/drive/MyDrive/ECE4424/Project/detection/darknet\n",
    "# !ls\n",
    "\n",
    "# # download pre-trained model\n",
    "# !wget https://pjreddie.com/media/files/darknet53.conv.74 -O /content/drive/MyDrive/ECE4424/Project/detection/darknet/darknet53.conv.74\n",
    "\n",
    "# build Darknet\n",
    "%cd /content/drive/MyDrive/ECE4424/Project/detection/darknet\n",
    "!make\n",
    "!chmod +x ./darknet\n",
    "\n",
    "# perform modifications to Darknet files for project usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5096,
     "status": "ok",
     "timestamp": 1647472104346,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "JBzOlx-kUUUB",
    "outputId": "adca6023-a2a9-4246-c788-7db572f2b361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  dos2unix\n",
      "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
      "Need to get 351 kB of archives.\n",
      "After this operation, 1,267 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dos2unix amd64 7.3.4-3 [351 kB]\n",
      "Fetched 351 kB in 1s (463 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package dos2unix.\n",
      "(Reading database ... 155335 files and directories currently installed.)\n",
      "Preparing to unpack .../dos2unix_7.3.4-3_amd64.deb ...\n",
      "Unpacking dos2unix (7.3.4-3) ...\n",
      "Setting up dos2unix (7.3.4-3) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "# install unix format conversion tool - dos2unix\n",
    "!sudo apt install dos2unix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2413,
     "status": "ok",
     "timestamp": 1647472108321,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "4koDm39TUfu9",
    "outputId": "22a2a1a3-9395-48f0-c5c1-d878cc475712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos2unix: converting file /content/drive/MyDrive/ECE4424/Project/detection/detection_data/detection_train.txt to Unix format...\n",
      "dos2unix: converting file /content/drive/MyDrive/ECE4424/Project/detection/detection_data/detection_test.txt to Unix format...\n",
      "dos2unix: converting file /content/drive/MyDrive/ECE4424/Project/detection/classes.names to Unix format...\n",
      "dos2unix: converting file /content/drive/MyDrive/ECE4424/Project/detection/yolov3.data to Unix format...\n",
      "dos2unix: converting file /content/drive/MyDrive/ECE4424/Project/detection/darknet-yolov3-train-custom.cfg to Unix format...\n",
      "dos2unix: converting file /content/drive/MyDrive/ECE4424/Project/detection/darknet-yolov3-test-custom.cfg to Unix format...\n"
     ]
    }
   ],
   "source": [
    "# re-format relevant files for training\n",
    "!dos2unix /content/drive/MyDrive/ECE4424/Project/detection/detection_data/detection_train.txt\n",
    "!dos2unix /content/drive/MyDrive/ECE4424/Project/detection/detection_data/detection_test.txt\n",
    "!dos2unix /content/drive/MyDrive/ECE4424/Project/detection/classes.names\n",
    "!dos2unix /content/drive/MyDrive/ECE4424/Project/detection/yolov3.data\n",
    "!dos2unix /content/drive/MyDrive/ECE4424/Project/detection/darknet-yolov3-train-custom.cfg\n",
    "!dos2unix /content/drive/MyDrive/ECE4424/Project/detection/darknet-yolov3-test-custom.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOp6mcAANr5A"
   },
   "source": [
    "### **YOLOv3 - Train the Model**###\n",
    "\n",
    "1.   Ensure GPU is enabled and connected\n",
    "2.   Utilize Darknet to train\n",
    "3.   Analyze training loss after completion\n",
    "\n",
    "Citation for Loss Visualization Code: https://learnopencv.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1647472110963,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "l2klDo7-UK03",
    "outputId": "700bdf61-a5f1-421a-8980-7eae25f2a6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 16 23:08:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# ensure GPU runtime is connnected\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIbygYC_Jzza"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "# change working directory to cloned Darknet directory in detection directory\n",
    "%cd /content/drive/MyDrive/ECE4424/Project/detection/darknet\n",
    "!ls\n",
    "!chmod +x ./darknet\n",
    "\n",
    "!./darknet detector train \\\n",
    "                          /content/drive/MyDrive/ECE4424/Project/detection/yolov3.data \\\n",
    "                          /content/drive/MyDrive/ECE4424/Project/detection/darknet-yolov3-train-custom.cfg \\\n",
    "                          ./darknet53.conv.74 \\\n",
    "                          | tee /content/drive/MyDrive/ECE4424/Project/detection/train.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 11282,
     "status": "ok",
     "timestamp": 1647526303568,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "ggRbUHQlMD5W",
    "outputId": "6eec2518-52d1-4139-ae95-c931d2bf3d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Plot saved as training_loss_plot.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize training loss - image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TRAIN_LOG_PATH = sys_path + \"/train.log\"                      # path to train log\n",
    "TRAIN_LOSS_IMG_PATH = sys_path + \"/training_loss_plot.png\"    # path to save training loss image\n",
    "\n",
    "lines = []\n",
    "for line in open(TRAIN_LOG_PATH):\n",
    "    if \"avg\" in line:\n",
    "        lines.append(line)\n",
    "\n",
    "iterations = []\n",
    "avg_loss = []\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    lineParts = lines[i].split(',')\n",
    "    iterations.append(int(lineParts[0].split(':')[0]))\n",
    "    avg_loss.append(float(lineParts[1].split()[0]))\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(0, len(lines)):\n",
    "    plt.plot(iterations[i:i+2], avg_loss[i:i+2], 'r.-')\n",
    "\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Avg Loss')\n",
    "plt.title('YOLOv3 License Plate Object Detection Loss')\n",
    "fig.savefig(TRAIN_LOSS_IMG_PATH, dpi=1000)\n",
    "\n",
    "print(\"[STATUS] Plot saved as training_loss_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-_aj0t0R1H4"
   },
   "outputs": [],
   "source": [
    "# visualize training loss - text\n",
    "!grep \"avg\" /content/drive/MyDrive/ECE4424/Project/detection/train.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1FlfVl0RHNr"
   },
   "source": [
    "### **YOLOv3 - Test the Model**###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190471,
     "status": "ok",
     "timestamp": 1647483576847,
     "user": {
      "displayName": "David Peterson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh5Ydm7mmqLMzn05Ur0j6UrbkoodWVnyUb7Wy2S=s64",
      "userId": "16473186079830766499"
     },
     "user_tz": 240
    },
    "id": "rmUBkigtSqZ9",
    "outputId": "f0fc03b8-8c28-48d1-ce2d-744bbba27d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/ECE4424/Project/detection/darknet\n",
      "backup\t\t   data\t\t  LICENSE\tLICENSE.mit\t python\n",
      "bad.list\t   examples\t  LICENSE.fuck\tLICENSE.v1\t README.md\n",
      "cfg\t\t   include\t  LICENSE.gen\tMakefile\t results\n",
      "darknet\t\t   libdarknet.a   LICENSE.gpl\tobj\t\t scripts\n",
      "darknet53.conv.74  libdarknet.so  LICENSE.meta\tpredictions.jpg  src\n",
      "layer     filters    size              input                output\n",
      "    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32  0.299 BFLOPs\n",
      "    1 conv     64  3 x 3 / 2   416 x 416 x  32   ->   208 x 208 x  64  1.595 BFLOPs\n",
      "    2 conv     32  1 x 1 / 1   208 x 208 x  64   ->   208 x 208 x  32  0.177 BFLOPs\n",
      "    3 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64  1.595 BFLOPs\n",
      "    4 res    1                 208 x 208 x  64   ->   208 x 208 x  64\n",
      "    5 conv    128  3 x 3 / 2   208 x 208 x  64   ->   104 x 104 x 128  1.595 BFLOPs\n",
      "    6 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64  0.177 BFLOPs\n",
      "    7 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128  1.595 BFLOPs\n",
      "    8 res    5                 104 x 104 x 128   ->   104 x 104 x 128\n",
      "    9 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64  0.177 BFLOPs\n",
      "   10 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128  1.595 BFLOPs\n",
      "   11 res    8                 104 x 104 x 128   ->   104 x 104 x 128\n",
      "   12 conv    256  3 x 3 / 2   104 x 104 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   13 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   14 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   15 res   12                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   16 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   17 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   18 res   15                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   19 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   20 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   21 res   18                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   22 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   23 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   24 res   21                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   25 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   26 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   27 res   24                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   28 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   29 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   30 res   27                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   31 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   32 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   33 res   30                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   34 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs\n",
      "   35 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs\n",
      "   36 res   33                  52 x  52 x 256   ->    52 x  52 x 256\n",
      "   37 conv    512  3 x 3 / 2    52 x  52 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   38 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   39 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   40 res   37                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   41 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   42 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   43 res   40                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   44 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   45 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   46 res   43                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   47 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   48 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   49 res   46                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   50 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   51 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   52 res   49                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   53 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   54 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   55 res   52                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   56 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   57 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   58 res   55                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   59 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   60 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   61 res   58                  26 x  26 x 512   ->    26 x  26 x 512\n",
      "   62 conv   1024  3 x 3 / 2    26 x  26 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   63 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   64 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   65 res   62                  13 x  13 x1024   ->    13 x  13 x1024\n",
      "   66 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   67 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   68 res   65                  13 x  13 x1024   ->    13 x  13 x1024\n",
      "   69 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   70 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   71 res   68                  13 x  13 x1024   ->    13 x  13 x1024\n",
      "   72 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   73 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   74 res   71                  13 x  13 x1024   ->    13 x  13 x1024\n",
      "   75 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   76 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   77 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   78 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   79 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs\n",
      "   80 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs\n",
      "   81 conv     18  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x  18  0.006 BFLOPs\n",
      "   82 yolo\n",
      "   83 route  79\n",
      "   84 conv    256  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x 256  0.044 BFLOPs\n",
      "   85 upsample            2x    13 x  13 x 256   ->    26 x  26 x 256\n",
      "   86 route  85 61\n",
      "   87 conv    256  1 x 1 / 1    26 x  26 x 768   ->    26 x  26 x 256  0.266 BFLOPs\n",
      "   88 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   89 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   90 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   91 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs\n",
      "   92 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs\n",
      "   93 conv     18  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x  18  0.012 BFLOPs\n",
      "   94 yolo\n",
      "   95 route  91\n",
      "   96 conv    128  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x 128  0.044 BFLOPs\n",
      "   97 upsample            4x    26 x  26 x 128   ->   104 x 104 x 128\n",
      "   98 route  97 11\n",
      "   99 conv    128  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x 128  0.709 BFLOPs\n",
      "  100 conv    256  3 x 3 / 1   104 x 104 x 128   ->   104 x 104 x 256  6.380 BFLOPs\n",
      "  101 conv    128  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x 128  0.709 BFLOPs\n",
      "  102 conv    256  3 x 3 / 1   104 x 104 x 128   ->   104 x 104 x 256  6.380 BFLOPs\n",
      "  103 conv    128  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x 128  0.709 BFLOPs\n",
      "  104 conv    256  3 x 3 / 1   104 x 104 x 128   ->   104 x 104 x 256  6.380 BFLOPs\n",
      "  105 conv     18  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x  18  0.100 BFLOPs\n",
      "  106 yolo\n",
      "Loading weights from /content/drive/MyDrive/ECE4424/Project/detection/detection_data/weights/darknet-yolov3-train-custom_final.weights...Done!\n",
      "/content/drive/MyDrive/ECE4424/Project/detection/detection_data/images/cars001.jpg: Predicted in 0.133294 seconds.\n",
      "license_plate: 100%\n",
      "Unable to init server: Could not connect: Connection refused\n",
      "\n",
      "(predictions:282): Gtk-\u001b[1;33mWARNING\u001b[0m **: \u001b[34m02:19:35.556\u001b[0m: cannot open display: \n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "%cd /content/drive/MyDrive/ECE4424/Project/detection/darknet\n",
    "!ls\n",
    "!chmod +x ./darknet\n",
    "\n",
    "!./darknet detector test \\\n",
    "                         /content/drive/MyDrive/ECE4424/Project/detection/yolov3.data \\\n",
    "                         /content/drive/MyDrive/ECE4424/Project/detection/darknet-yolov3-test-custom.cfg \\\n",
    "                         /content/drive/MyDrive/ECE4424/Project/detection/detection_data/weights/darknet-yolov3-train-custom_final.weights \\\n",
    "                         /content/drive/MyDrive/ECE4424/Project/detection/detection_data/images/cars001.jpg"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
